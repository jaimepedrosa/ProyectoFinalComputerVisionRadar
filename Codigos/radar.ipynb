{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAB PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26 in c:\\users\\ignac\\icai\\3 curso\\1 cuatri\\vision por ordenador i\\laboratorio\\lab_project\\labproject\\lib\\site-packages (1.26.0)\n",
      "Requirement already satisfied: opencv-python==4.8.0.76 in c:\\users\\ignac\\icai\\3 curso\\1 cuatri\\vision por ordenador i\\laboratorio\\lab_project\\labproject\\lib\\site-packages (4.8.0.76)\n",
      "Requirement already satisfied: imageio in c:\\users\\ignac\\icai\\3 curso\\1 cuatri\\vision por ordenador i\\laboratorio\\lab_project\\labproject\\lib\\site-packages (2.36.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\ignac\\icai\\3 curso\\1 cuatri\\vision por ordenador i\\laboratorio\\lab_project\\labproject\\lib\\site-packages (from imageio) (11.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26 opencv-python==4.8.0.76 imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import threading\n",
    "from rastreador import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(videopath):\n",
    "\n",
    "    #TODO: Complete this line to read the video file\n",
    "    cap = cv2.VideoCapture(videopath) \n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print('Error: Could not open the video file')\n",
    "        return None\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) # Get the width of the video frames\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # Get the height of the video frames\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS) # Get the frame rate of the video\n",
    "    \n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    return frames, frame_width, frame_height, frame_rate\n",
    "\n",
    "videopath = '../assets/video_coche.mov'\n",
    "\n",
    "frames, frame_width, frame_height, frame_rate = read_video(videopath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen guardada en: C:\\Users\\ignac\\ICAI\\3 CURSO\\1 CUATRI\\VISION POR ORDENADOR I\\LABORATORIO\\Lab_Project\\assets\\primera_imagen.jpg\n"
     ]
    }
   ],
   "source": [
    "### Este codigo ha sido creado para poder crear una imagen del primer frame y asi poder detectar correctamente los pÃ­xeles para poder\n",
    "### delimitar correctamente las zonas donde vamos a detectar y calcular la velocidad\n",
    "\n",
    "image_path = r\"C:\\Users\\ignac\\ICAI\\3 CURSO\\1 CUATRI\\VISION POR ORDENADOR I\\LABORATORIO\\Lab_Project\\assets\\primera_imagen.jpg\"\n",
    "\n",
    "# Guardar la primera imagen\n",
    "cv2.imwrite(image_path, frames[0])\n",
    "print(f\"Imagen guardada en: {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carI = {}\n",
    "\n",
    "tracker = Rastreador()\n",
    "deteccion = cv2.createBackgroundSubtractorMOG2(history=10000,varThreshold=100)\n",
    "\n",
    "i = 0\n",
    "num_frame_actual = 0\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"../assets/video_coche.mov\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    height = frame.shape[0]\n",
    "    weight = frame.shape[1]\n",
    "\n",
    "    mask = np.zeros((height,weight),dtype=np.uint8)\n",
    "\n",
    "    ptos = np.array([[140,195],[198,195],[204,430],[21,430]])\n",
    "\n",
    "    cv2.fillPoly(mask,[ptos],255)\n",
    "\n",
    "    zona = cv2.bitwise_and(frame,frame,mask=mask)\n",
    "\n",
    "    areag = np.array([[140,195],[198,195],[204,430],[21,430]])\n",
    "    area1 = np.array([[74,320],[198,320],[204,430],[21,430]])\n",
    "    area2 = np.array([[104,265],[199,265],[198,320],[74,320]])\n",
    "    area3 = np.array([[140,195],[198,195],[199,265],[104,265]])\n",
    "\n",
    "    cv2.polylines(frame, [np.array(areag,np.int32)], True, (255,255,0), 2)\n",
    "    cv2.polylines(frame, [np.array(area3,np.int32)], True, (0,130,255), 1)\n",
    "    cv2.polylines(frame, [np.array(area2,np.int32)], True, (0,0,255), 1)\n",
    "    cv2.polylines(frame, [np.array(area2,np.int32)], True, (0,130,255), 1)\n",
    "\n",
    "    mascara = deteccion.apply(zona)\n",
    "\n",
    "    filtro = cv2.GaussianBlur(mascara,(11,11),0)\n",
    "\n",
    "    _,umbral = cv2.threshold(filtro,50,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    dila = cv2.dilate(umbral, np.ones((3, 3), dtype=np.uint8))\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "\n",
    "    cerrar = cv2.morphologyEx(dila,cv2.MORPH_CLOSE,kernel)\n",
    "\n",
    "    contornos, _ = cv2.findContours(cerrar,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    detecciones = []\n",
    "\n",
    "    for cont in contornos:\n",
    "        area = cv2.contourArea(cont)\n",
    "        if area >1000:\n",
    "            x,y,ancho,alto = cv2.boundingRect(cont)\n",
    "\n",
    "            detecciones.append([x,y,ancho,alto])\n",
    "    \n",
    "    info_id = tracker.rastreo(detecciones)\n",
    "\n",
    "    for inf in info_id:\n",
    "        x,y,ancho,alto, id = inf\n",
    "\n",
    "        cv2.rectangle(frame, (x,y-10),(x+ancho,y+alto),(0,0,255),2)\n",
    "\n",
    "        cx = int(x+ancho /2)\n",
    "        cy = int(y+alto /2)\n",
    "\n",
    "        a2 = cv2.pointPolygonTest(np.array(area2,np.int32),(cx,cy),False)\n",
    "\n",
    "        if a2 >= 0 and id not in carI:\n",
    "            carI[id] = num_frame_actual\n",
    "\n",
    "        if id in carI:\n",
    "            cv2.circle(frame, (cx,cy),3,(0,0,255),-1)\n",
    "\n",
    "            a3 = cv2.pointPolygonTest(np.array(area3,np.int32),(cx,cy),False)\n",
    "\n",
    "            if a3 >= 0:\n",
    "                i += 1\n",
    "                n_frames = num_frame_actual-carI[id]\n",
    "                tiempo = n_frames/30\n",
    "                print(f\"Tiempo transcurrido: {tiempo}\")\n",
    "\n",
    "                vel = (0.15/tiempo)*36\n",
    "                print(f\"ID: {id}, Velocidad: {vel} km/h\")\n",
    "                #del carI[id]\n",
    "\n",
    "                cv2.rectangle(frame,(x,y-10),(x+100,y-50),(0,0,255),-1)\n",
    "                cv2.putText(frame,str(int(vel)) + \" KM/H\", (x,y-35), cv2.FONT_HERSHEY_PLAIN,1,(255,255,255),2)\n",
    "\n",
    "    cv2.imshow(\"Video\",frame)\n",
    "    num_frame_actual += 1\n",
    "    #print(i)\n",
    "    if cv2.waitKey(100//30) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyWindow(\"Video\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LabProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
